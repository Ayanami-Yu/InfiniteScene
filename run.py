import os
import argparse
import json
from PIL import Image

# from luciddreamer import LucidDreamer
from dreamer import Dreamer
from gen_powers_10.utils import seed_everything


if __name__ == "__main__":
    # option
    parser = argparse.ArgumentParser(description="Arguments for LucidDreamer")
    # Input options
    parser.add_argument(
        "--image",
        "-img",
        type=str,
        # default="examples/Image015_animelakehouse.jpg",
        default="examples/hawaii3.png",
        # default=None,
        help="Input image for scene generation. If not provided, the conditioning image will be the most zoomed-out image generated by Powers of Ten.",
    )
    parser.add_argument(
        "--text",
        "-t",
        type=str,
        # default="examples/Image015_animelakehouse.txt",
        # default="examples/hawaii.txt",
        default="examples/hawaii.json",
        help="Text prompt for scene generation",
    )
    parser.add_argument(
        "--neg_text",
        "-nt",
        type=str,
        # default="",
        default="artifacts, blurry, smooth texture, bad quality, distortions, unrealistic, distorted image",
        help="Negative text prompt for scene generation",
    )

    # Camera options
    parser.add_argument(
        "--campath_gen",
        "-cg",
        type=str,
        default="lookdown",
        choices=["lookdown", "lookaround", "rotate360"],
        help="Camera extrinsic trajectories for scene generation",
    )
    parser.add_argument(
        "--campath_render",
        "-cr",
        type=str,
        default="headbanging",
        choices=["back_and_forth", "llff", "headbanging"],
        help="Camera extrinsic trajectories for video rendering",
    )

    # Inpainting options
    parser.add_argument(
        "--model_name",
        type=str,
        default=None,
        help="Model name for inpainting(dreaming)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        # default=1,
        default=83920174658,
        help="Manual seed for running Stable Diffusion inpainting",
    )
    parser.add_argument(
        "--diff_steps",
        type=int,
        default=50,
        help="Number of inference steps for running Stable Diffusion inpainting",
    )
    parser.add_argument(
        "--version",
        type=str,
        default="DFIF_XL_L_X4",
        help="T2I model for Powers of Ten",
    )  # {XL, L, M}_{L, M}

    # Save options
    parser.add_argument("--save_dir", "-s", type=str, default="", help="Save directory")

    args = parser.parse_args()
    seed_everything(args.seed)

    # input (example)
    rgb_cond = Image.open(args.image) if args.image else None

    metadata = None
    if args.text.endswith(".txt"):
        with open(args.text, "r") as f:
            txt_cond = f.readline()
    elif args.text.endswith(".json"):
        with open(args.text, "r") as f:
            metadata = json.load(f)
            txt_cond = metadata["prompts"]
    else:
        txt_cond = args.text

    if args.neg_text.endswith(".txt"):
        with open(args.neg_text, "r") as f:
            neg_txt_cond = f.readline()
    else:
        neg_txt_cond = args.neg_text

    # Make default save directory if blank
    if args.save_dir == "":
        img_name = os.path.splitext(os.path.basename(args.text))[0]
        args.save_dir = f"./outputs/{img_name}_{args.campath_gen}_{args.seed}"
    if not os.path.exists(args.save_dir):
        os.makedirs(args.save_dir, exist_ok=True)

    if args.model_name is not None and args.model_name.endswith("safetensors"):
        print("Your model is saved in safetensor form. Converting to HF models...")
        from diffusers.pipelines.stable_diffusion.convert_from_ckpt import (
            download_from_original_stable_diffusion_ckpt,
        )

        pipe = download_from_original_stable_diffusion_ckpt(
            checkpoint_path_or_dict=args.model_name,
            from_safetensors=True,
            device="cuda",
        )
        pipe.save_pretrained("stablediffusion/", safe_serialization=False)
        args.model_name = f"stablediffusion/{args.model_name}"

    ld = Dreamer(for_gradio=False, save_dir=args.save_dir, version=args.version)
    ld.create(
        rgb_cond,
        txt_cond,
        neg_txt_cond,
        args.campath_gen,
        args.seed,
        args.diff_steps,
        # model_name=args.model_name,
        p=metadata["p"] if metadata else None,
    )
    # ld.render_video_preset(args.campath_render)
    # ld.render_video_preset("back_and_forth")
    ld.render_video_preset("llff")
    ld.render_video_preset("headbanging")
    # ld.render_video_preset("tapered")  # TODO test
    ld.render_video_preset("diving")
